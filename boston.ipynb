{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fresh_boston_data(keep_locations=False):\n",
    "    weird_dtypes = {\n",
    "        s: 'object' for s in [\n",
    "            'INCIDENT_NUMBER',\n",
    "            'OFFENSE_CODE_GROUP',\n",
    "            'OFFENSE_DESCRIPTION',\n",
    "            'DISTRICT',\n",
    "            'REPORTING_AREA',\n",
    "            'SHOOTING',\n",
    "            'OCCURRED_ON_DATE',\n",
    "            'DAY_OF_WEEK',\n",
    "            'UCR_PART',\n",
    "            'STREET'\n",
    "        ]\n",
    "    }\n",
    "    df = pd.read_csv(\"boston_crime.csv\",encoding = \"ISO-8859-1\",dtype=weird_dtypes)\n",
    "    df.rename({name : name.lower() for name in df.columns}, axis=1, inplace=True)\n",
    "    df[\"shooting\"] = df[\"shooting\"] == 'Y'\n",
    "    \n",
    "    \n",
    "    ############# nominal / ordinal encoding #############\n",
    "    \n",
    "    \n",
    "    # ucr_part is nominal (part I is the most extreme)\n",
    "    # We use one-hot encoding similar to that done on the prelim;\n",
    "    # 'ucr_le_two' indicates that it was less severe than part 1 (i.e., part 2, part 3, or part 4)\n",
    "    # (note that part 3 is less severe than part 2)\n",
    "    \n",
    "    df[\"ucr_part\"].fillna(\"Other\",inplace=True) # we assume that most NaN are the same as \"Other\"\n",
    "    \n",
    "    def real_encode_ucr(s):\n",
    "        num = s.rsplit(\" \", 1)[-1]\n",
    "        if num == \"One\":\n",
    "            return 1\n",
    "        if num == \"Two\":\n",
    "            return 2\n",
    "        if num == \"Three\":\n",
    "            return 3\n",
    "        if num == \"Other\":\n",
    "            return 4 \n",
    "            # We want \"Other\" and NaN to be represented as \"no information\".\n",
    "            # We encode it as 4 (less severe than the least severe code), so \n",
    "            # that it will be encoded as \"1\" in all three features we generate below.\n",
    "            # We hope that this will provide the least biased information.\n",
    "    \n",
    "    real_encoded_ucr_part = df[\"ucr_part\"].apply(real_encode_ucr)\n",
    "    \n",
    "    df[\"ucr_lt_1\"] = real_encoded_ucr_part > 1 # \"le\" stands for \"severity less than\"\n",
    "    df[\"ucr_lt_2\"] = real_encoded_ucr_part > 2\n",
    "    df[\"ucr_lt_3\"] = real_encoded_ucr_part > 3 \n",
    "    # note that 4 is a fake part that we made up to deal with missing data\n",
    "    \n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].apply(lambda s: s == \"Saturday\" or s == \"Sunday\")\n",
    "    \n",
    "    if keep_locations:\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    ################## do processing in order to be blind to neighborhood location #############\n",
    "    df.drop(labels=[\"incident_number\"], axis=1, inplace=True)\n",
    "    \n",
    "    # drop latitude and longitude\n",
    "    df.drop(labels=[\"lat\",\"long\",\"location\",\"district\",\"reporting_area\"], axis=1, inplace=True)\n",
    "    \n",
    "    # reporting_area\n",
    "    df[\"street_type\"] = df[\"street\"].apply(lambda s: \"\" if not isinstance(s,str) else s.rsplit(\" \", 1)[-1])\n",
    "    street_counts = df[\"street_type\"].value_counts()\n",
    "    def replace_streets(streetpostfix):\n",
    "        common_street_names = [\n",
    "            'BROADWAY','TER',''\n",
    "            \n",
    "        ]\n",
    "        if (street_counts[streetpostfix] < 350 or streetpostfix in common_street_names):\n",
    "            return \"OTHER\"\n",
    "        return streetpostfix\n",
    "    df[\"street_type\"] = df[\"street_type\"].apply(replace_streets)\n",
    "    df.drop(labels=[\"street\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_stats(xs,indent=0):\n",
    "    init_tabs = \" \"*indent\n",
    "    print(init_tabs+\"mean:\\t\", np.mean(xs))\n",
    "    print(init_tabs+\"median:\\t\", np.median(xs))\n",
    "    print(init_tabs+\"mode:\\t\", np.unique(xs)[-1])\n",
    "    print(init_tabs+\"sd:\\t\", np.std(xs))\n",
    "    print(init_tabs+\"min:\\t\", np.min(xs))\n",
    "    print(init_tabs+\"max:\\t\", np.max(xs))\n",
    "    print(init_tabs+\"count:\\t\", len(xs))\n",
    "    print(init_tabs+\"missing:\", sum(np.isnan(xs)))\n",
    "    \n",
    "    print(init_tabs+\"Percentiles:\")\n",
    "    for p in [10,25,50,75,90]:\n",
    "        print(init_tabs+\"\\t\",str(p) + \"%:\", np.percentile(xs,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_shooting_data(train_percentage=None,test_percentage=0.2):\n",
    "    if train_percentage == None:\n",
    "        train_percentage = 1 - test_percentage\n",
    "    train_size = len(df.index) * train_percentage\n",
    "    train = set()\n",
    "    test = set()\n",
    "    shootings_list = [i for i in range(len(df.index)) if df.loc[i,\"shooting\"] == True]\n",
    "    shootings = set(shootings_list)\n",
    "    nonshootings = set(i for i in range(len(df.index)) if i not in shootings)\n",
    "    \n",
    "    num_shootings = len(shootings)\n",
    "    num_nonshootings = len(nonshootings)\n",
    "    \n",
    "    for i in np.random.choice(list(shootings), int(train_percentage * num_shootings), replace=False):\n",
    "        train.add(i)\n",
    "    for i in np.random.choice(list(nonshootings), int(train_percentage * num_nonshootings), replace=False):\n",
    "        train.add(i)\n",
    "    \n",
    "    for i in train:\n",
    "        if i in shootings:\n",
    "            shootings.remove(i)\n",
    "        else:\n",
    "            nonshootings.remove(i)\n",
    "    for i in np.random.choice(list(shootings), int(test_percentage * num_shootings), replace=False):\n",
    "        test.add(i)\n",
    "    for i in np.random.choice(list(nonshootings), int(test_percentage * num_nonshootings), replace=False):\n",
    "        test.add(i)\n",
    "    \n",
    "    return list(train), list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_fresh_boston_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
